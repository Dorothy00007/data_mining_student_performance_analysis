{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e94bb7c9-74c2-4f82-bb3e-9f8c9fd841c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Sample data generated with 500 students\n",
      "ðŸš€ API running at http://localhost:5000\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.1.91:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    }
   ],
   "source": [
    "# app.py - Student Performance Analytics API\n",
    "\n",
    "from flask import Flask, request, jsonify, send_file\n",
    "from flask_cors import CORS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import io\n",
    "import base64\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # Enable CORS for all routes\n",
    "\n",
    "# Global variables to store data and models\n",
    "student_data = None\n",
    "trained_models = {}\n",
    "\n",
    "# ============================================\n",
    "# Helper Functions\n",
    "# ============================================\n",
    "\n",
    "def generate_sample_data(n_students=500):\n",
    "    \"\"\"Generate sample student data\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    data = {\n",
    "        'StudentID': range(1001, 1001 + n_students),\n",
    "        'Age': np.random.choice([15, 16, 17, 18], n_students),\n",
    "        'Gender': np.random.choice([0, 1], n_students),\n",
    "        'Ethnicity': np.random.choice([0, 1, 2, 3], n_students),\n",
    "        'ParentalEducation': np.random.choice([0, 1, 2, 3, 4], n_students),\n",
    "        'StudyTimeWeekly': np.random.uniform(0, 20, n_students),\n",
    "        'Absences': np.random.poisson(5, n_students),\n",
    "        'Tutoring': np.random.choice([0, 1], n_students, p=[0.7, 0.3]),\n",
    "        'ParentalSupport': np.random.choice([0, 1, 2, 3, 4], n_students),\n",
    "        'Extracurricular': np.random.choice([0, 1], n_students, p=[0.6, 0.4]),\n",
    "        'Sports': np.random.choice([0, 1], n_students, p=[0.55, 0.45]),\n",
    "        'Music': np.random.choice([0, 1], n_students, p=[0.65, 0.35]),\n",
    "        'Volunteering': np.random.choice([0, 1], n_students, p=[0.7, 0.3])\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Calculate GPA\n",
    "    df['GPA'] = (2.0 + \n",
    "                 df['StudyTimeWeekly'] * 0.08 - \n",
    "                 df['Absences'] * 0.05 + \n",
    "                 df['ParentalSupport'] * 0.15 +\n",
    "                 df['Tutoring'] * 0.3 +\n",
    "                 (df['Extracurricular'] + df['Sports'] + df['Music'] + df['Volunteering']) * 0.1 +\n",
    "                 np.random.normal(0, 0.3, n_students))\n",
    "    df['GPA'] = df['GPA'].clip(0, 4)\n",
    "    \n",
    "    # Calculate Grade Class\n",
    "    df['GradeClass'] = pd.cut(df['GPA'], bins=[0, 1, 2, 3, 4], labels=[3, 2, 1, 0]).astype(float)\n",
    "    \n",
    "    # Add total activities\n",
    "    df['TotalActivities'] = df[['Tutoring', 'Extracurricular', 'Sports', 'Music', 'Volunteering']].sum(axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fig_to_base64(fig):\n",
    "    \"\"\"Convert matplotlib figure to base64 string\"\"\"\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='png', bbox_inches='tight', dpi=100)\n",
    "    buf.seek(0)\n",
    "    img_str = base64.b64encode(buf.read()).decode('utf-8')\n",
    "    plt.close(fig)\n",
    "    return img_str\n",
    "\n",
    "def prepare_features(df, features_list):\n",
    "    \"\"\"Prepare features for modeling\"\"\"\n",
    "    X = df[features_list].copy()\n",
    "    \n",
    "    # Handle missing values\n",
    "    X = X.fillna(X.mean())\n",
    "    \n",
    "    return X\n",
    "\n",
    "# ============================================\n",
    "# API Routes - Data Management\n",
    "# ============================================\n",
    "\n",
    "@app.route('/', methods=['GET'])\n",
    "def home():\n",
    "    \"\"\"API home endpoint\"\"\"\n",
    "    return jsonify({\n",
    "        'name': 'Student Performance Analytics API',\n",
    "        'version': '1.0',\n",
    "        'endpoints': {\n",
    "            '/data/upload': 'POST - Upload student data CSV',\n",
    "            '/data/generate': 'POST - Generate sample data',\n",
    "            '/data/summary': 'GET - Get data summary',\n",
    "            '/data/statistics': 'GET - Get statistical summary',\n",
    "            '/visualizations/dashboard': 'GET - Get dashboard visualizations',\n",
    "            '/visualizations/correlation': 'GET - Get correlation matrix',\n",
    "            '/analysis/feature-importance': 'POST - Get feature importance',\n",
    "            '/predict/risk': 'POST - Predict student risk',\n",
    "            '/predict/gpa': 'POST - Predict GPA',\n",
    "            '/predict/grade': 'POST - Predict grade class',\n",
    "            '/cluster/students': 'POST - Cluster students',\n",
    "            '/models/train': 'POST - Train ML model',\n",
    "            '/models/list': 'GET - List trained models'\n",
    "        }\n",
    "    })\n",
    "\n",
    "@app.route('/data/upload', methods=['POST'])\n",
    "def upload_data():\n",
    "    \"\"\"Upload student data CSV file\"\"\"\n",
    "    global student_data\n",
    "    \n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file provided'}), 400\n",
    "    \n",
    "    file = request.files['file']\n",
    "    \n",
    "    if file.filename == '':\n",
    "        return jsonify({'error': 'No file selected'}), 400\n",
    "    \n",
    "    try:\n",
    "        student_data = pd.read_csv(file)\n",
    "        \n",
    "        # Add derived features\n",
    "        if 'GPA' in student_data.columns:\n",
    "            if 'TotalActivities' not in student_data.columns:\n",
    "                activity_cols = [c for c in ['Tutoring', 'Extracurricular', 'Sports', 'Music', 'Volunteering'] \n",
    "                               if c in student_data.columns]\n",
    "                if activity_cols:\n",
    "                    student_data['TotalActivities'] = student_data[activity_cols].sum(axis=1)\n",
    "        \n",
    "        return jsonify({\n",
    "            'message': 'Data uploaded successfully',\n",
    "            'shape': student_data.shape,\n",
    "            'columns': student_data.columns.tolist()\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 400\n",
    "\n",
    "@app.route('/data/generate', methods=['POST'])\n",
    "def generate_data():\n",
    "    \"\"\"Generate sample student data\"\"\"\n",
    "    global student_data\n",
    "    \n",
    "    n_students = request.json.get('n_students', 500) if request.json else 500\n",
    "    student_data = generate_sample_data(n_students)\n",
    "    \n",
    "    return jsonify({\n",
    "        'message': f'Sample data generated with {n_students} students',\n",
    "        'shape': student_data.shape,\n",
    "        'columns': student_data.columns.tolist()\n",
    "    })\n",
    "\n",
    "@app.route('/data/summary', methods=['GET'])\n",
    "def data_summary():\n",
    "    \"\"\"Get basic data summary\"\"\"\n",
    "    global student_data\n",
    "    \n",
    "    if student_data is None:\n",
    "        return jsonify({'error': 'No data loaded. Please upload or generate data first.'}), 400\n",
    "    \n",
    "    summary = {\n",
    "        'total_students': len(student_data),\n",
    "        'total_features': len(student_data.columns),\n",
    "        'columns': student_data.columns.tolist(),\n",
    "        'data_types': student_data.dtypes.astype(str).to_dict(),\n",
    "        'missing_values': student_data.isnull().sum().to_dict(),\n",
    "        'sample_records': student_data.head(5).to_dict('records')\n",
    "    }\n",
    "    \n",
    "    return jsonify(summary)\n",
    "\n",
    "@app.route('/data/statistics', methods=['GET'])\n",
    "def data_statistics():\n",
    "    \"\"\"Get statistical summary\"\"\"\n",
    "    global student_data\n",
    "    \n",
    "    if student_data is None:\n",
    "        return jsonify({'error': 'No data loaded'}), 400\n",
    "    \n",
    "    # Get numeric columns only\n",
    "    numeric_cols = student_data.select_dtypes(include=[np.number]).columns\n",
    "    stats = student_data[numeric_cols].describe().to_dict()\n",
    "    \n",
    "    return jsonify(stats)\n",
    "\n",
    "# ============================================\n",
    "# API Routes - Visualizations\n",
    "# ============================================\n",
    "\n",
    "@app.route('/visualizations/dashboard', methods=['GET'])\n",
    "def get_dashboard():\n",
    "    \"\"\"Get dashboard visualizations as base64 images\"\"\"\n",
    "    global student_data\n",
    "    \n",
    "    if student_data is None:\n",
    "        return jsonify({'error': 'No data loaded'}), 400\n",
    "    \n",
    "    visualizations = {}\n",
    "    \n",
    "    # 1. GPA Distribution\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.hist(student_data['GPA'], bins=20, edgecolor='black', color='skyblue', alpha=0.7)\n",
    "    ax.set_title('GPA Distribution')\n",
    "    ax.set_xlabel('GPA')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    visualizations['gpa_distribution'] = fig_to_base64(fig)\n",
    "    \n",
    "    # 2. Study Time vs GPA\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.scatter(student_data['StudyTimeWeekly'], student_data['GPA'], alpha=0.5, color='green')\n",
    "    ax.set_xlabel('Study Time (hours/week)')\n",
    "    ax.set_ylabel('GPA')\n",
    "    ax.set_title('Study Time vs GPA')\n",
    "    visualizations['study_vs_gpa'] = fig_to_base64(fig)\n",
    "    \n",
    "    # 3. Absences vs GPA\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.scatter(student_data['Absences'], student_data['GPA'], alpha=0.5, color='red')\n",
    "    ax.set_xlabel('Number of Absences')\n",
    "    ax.set_ylabel('GPA')\n",
    "    ax.set_title('Absences vs GPA')\n",
    "    visualizations['absences_vs_gpa'] = fig_to_base64(fig)\n",
    "    \n",
    "    # 4. Parental Support Impact\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    support_means = student_data.groupby('ParentalSupport')['GPA'].mean()\n",
    "    ax.bar(range(len(support_means)), support_means.values, color='purple', edgecolor='black')\n",
    "    ax.set_xlabel('Parental Support Level')\n",
    "    ax.set_ylabel('Average GPA')\n",
    "    ax.set_title('Parental Support vs GPA')\n",
    "    visualizations['parental_support'] = fig_to_base64(fig)\n",
    "    \n",
    "    return jsonify(visualizations)\n",
    "\n",
    "@app.route('/visualizations/correlation', methods=['GET'])\n",
    "def get_correlation():\n",
    "    \"\"\"Get correlation matrix heatmap\"\"\"\n",
    "    global student_data\n",
    "    \n",
    "    if student_data is None:\n",
    "        return jsonify({'error': 'No data loaded'}), 400\n",
    "    \n",
    "    numeric_cols = student_data.select_dtypes(include=[np.number]).columns\n",
    "    corr_matrix = student_data[numeric_cols].corr()\n",
    "    \n",
    "    # Create heatmap\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "                square=True, linewidths=1, cbar_kws={\"shrink\": 0.8}, ax=ax)\n",
    "    ax.set_title('Feature Correlation Matrix')\n",
    "    \n",
    "    # Get correlations with GPA\n",
    "    gpa_corr = {}\n",
    "    if 'GPA' in corr_matrix.columns:\n",
    "        gpa_corr = corr_matrix['GPA'].drop('GPA').sort_values(ascending=False).to_dict()\n",
    "    \n",
    "    return jsonify({\n",
    "        'correlation_matrix': corr_matrix.to_dict(),\n",
    "        'correlation_heatmap': fig_to_base64(fig),\n",
    "        'gpa_correlations': gpa_corr\n",
    "    })\n",
    "\n",
    "# ============================================\n",
    "# API Routes - Predictions\n",
    "# ============================================\n",
    "\n",
    "@app.route('/predict/risk', methods=['POST'])\n",
    "def predict_risk():\n",
    "    \"\"\"Predict student risk level\"\"\"\n",
    "    global student_data\n",
    "    \n",
    "    if student_data is None:\n",
    "        return jsonify({'error': 'No data loaded'}), 400\n",
    "    \n",
    "    data = request.json\n",
    "    \n",
    "    # Extract features\n",
    "    features = ['StudyTimeWeekly', 'Absences', 'ParentalSupport', 'TotalActivities']\n",
    "    \n",
    "    # Prepare input\n",
    "    input_data = pd.DataFrame([{\n",
    "        'StudyTimeWeekly': data.get('study_time', 10),\n",
    "        'Absences': data.get('absences', 5),\n",
    "        'ParentalSupport': data.get('parental_support', 2),\n",
    "        'TotalActivities': data.get('activities', 2)\n",
    "    }])\n",
    "    \n",
    "    # Train model\n",
    "    X = student_data[features]\n",
    "    y = student_data['GPA']\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Predict\n",
    "    pred_gpa = model.predict(input_data)[0]\n",
    "    \n",
    "    # Determine risk\n",
    "    if pred_gpa >= 3.0:\n",
    "        risk_level = 'Low Risk'\n",
    "        risk_color = 'green'\n",
    "        recommendation = 'Student is performing well. Keep up the good work!'\n",
    "    elif pred_gpa >= 2.0:\n",
    "        risk_level = 'Medium Risk'\n",
    "        risk_color = 'orange'\n",
    "        recommendation = 'Student shows some risk factors. Consider additional support.'\n",
    "    else:\n",
    "        risk_level = 'High Risk'\n",
    "        risk_color = 'red'\n",
    "        recommendation = 'Student needs immediate intervention and academic support.'\n",
    "    \n",
    "    return jsonify({\n",
    "        'predicted_gpa': round(float(pred_gpa), 2),\n",
    "        'risk_level': risk_level,\n",
    "        'risk_color': risk_color,\n",
    "        'recommendation': recommendation,\n",
    "        'input_features': input_data.to_dict('records')[0]\n",
    "    })\n",
    "\n",
    "@app.route('/predict/gpa', methods=['POST'])\n",
    "def predict_gpa():\n",
    "    \"\"\"Predict GPA based on student features\"\"\"\n",
    "    global student_data\n",
    "    \n",
    "    if student_data is None:\n",
    "        return jsonify({'error': 'No data loaded'}), 400\n",
    "    \n",
    "    data = request.json\n",
    "    \n",
    "    # Define features\n",
    "    feature_cols = ['StudyTimeWeekly', 'Absences', 'ParentalSupport', 'Tutoring', \n",
    "                   'Extracurricular', 'Sports', 'Music', 'Volunteering']\n",
    "    \n",
    "    # Prepare input\n",
    "    input_data = {}\n",
    "    for col in feature_cols:\n",
    "        input_data[col] = data.get(col.lower(), 0)\n",
    "    \n",
    "    input_df = pd.DataFrame([input_data])\n",
    "    \n",
    "    # Train model\n",
    "    X = student_data[feature_cols]\n",
    "    y = student_data['GPA']\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Predict\n",
    "    pred_gpa = model.predict(input_df)[0]\n",
    "    \n",
    "    # Get confidence interval (simplified)\n",
    "    predictions = []\n",
    "    for estimator in model.estimators_:\n",
    "        predictions.append(estimator.predict(input_df)[0])\n",
    "    \n",
    "    confidence_lower = np.percentile(predictions, 2.5)\n",
    "    confidence_upper = np.percentile(predictions, 97.5)\n",
    "    \n",
    "    return jsonify({\n",
    "        'predicted_gpa': round(float(pred_gpa), 3),\n",
    "        'confidence_interval': {\n",
    "            'lower': round(float(confidence_lower), 3),\n",
    "            'upper': round(float(confidence_upper), 3)\n",
    "        },\n",
    "        'input_features': input_data\n",
    "    })\n",
    "\n",
    "@app.route('/predict/grade', methods=['POST'])\n",
    "def predict_grade():\n",
    "    \"\"\"Predict grade class\"\"\"\n",
    "    global student_data\n",
    "    \n",
    "    if student_data is None:\n",
    "        return jsonify({'error': 'No data loaded'}), 400\n",
    "    \n",
    "    data = request.json\n",
    "    \n",
    "    # Define features\n",
    "    feature_cols = ['StudyTimeWeekly', 'Absences', 'ParentalSupport', 'TotalActivities']\n",
    "    \n",
    "    # Prepare input\n",
    "    input_data = {}\n",
    "    for col in feature_cols:\n",
    "        input_data[col] = data.get(col.lower(), 0)\n",
    "    \n",
    "    input_df = pd.DataFrame([input_data])\n",
    "    \n",
    "    # Train model\n",
    "    X = student_data[feature_cols]\n",
    "    y = student_data['GradeClass']\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Predict\n",
    "    pred_class = model.predict(input_df)[0]\n",
    "    pred_proba = model.predict_proba(input_df)[0].tolist()\n",
    "    \n",
    "    # Grade class mapping\n",
    "    grade_map = {0: 'A (Highest)', 1: 'B', 2: 'C', 3: 'D (Lowest)'}\n",
    "    \n",
    "    return jsonify({\n",
    "        'predicted_grade_class': int(pred_class),\n",
    "        'grade_label': grade_map.get(int(pred_class), 'Unknown'),\n",
    "        'prediction_probabilities': pred_proba,\n",
    "        'input_features': input_data\n",
    "    })\n",
    "\n",
    "# ============================================\n",
    "# API Routes - Analysis\n",
    "# ============================================\n",
    "\n",
    "@app.route('/analysis/feature-importance', methods=['POST'])\n",
    "def feature_importance():\n",
    "    \"\"\"Get feature importance for prediction\"\"\"\n",
    "    global student_data\n",
    "    \n",
    "    if student_data is None:\n",
    "        return jsonify({'error': 'No data loaded'}), 400\n",
    "    \n",
    "    data = request.json\n",
    "    target = data.get('target', 'GPA')\n",
    "    \n",
    "    # Define features\n",
    "    feature_cols = ['StudyTimeWeekly', 'Absences', 'ParentalSupport', 'Tutoring', \n",
    "                   'Extracurricular', 'Sports', 'Music', 'Volunteering', 'TotalActivities']\n",
    "    \n",
    "    X = student_data[feature_cols]\n",
    "    \n",
    "    if target == 'GPA':\n",
    "        y = student_data['GPA']\n",
    "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    else:\n",
    "        y = student_data['GradeClass']\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Get feature importance\n",
    "    importance = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    return jsonify({\n",
    "        'target': target,\n",
    "        'feature_importance': importance.to_dict('records')\n",
    "    })\n",
    "\n",
    "@app.route('/cluster/students', methods=['POST'])\n",
    "def cluster_students():\n",
    "    \"\"\"Perform K-means clustering on students\"\"\"\n",
    "    global student_data\n",
    "    \n",
    "    if student_data is None:\n",
    "        return jsonify({'error': 'No data loaded'}), 400\n",
    "    \n",
    "    data = request.json\n",
    "    n_clusters = data.get('n_clusters', 4)\n",
    "    features = data.get('features', ['StudyTimeWeekly', 'Absences', 'GPA'])\n",
    "    \n",
    "    # Prepare data\n",
    "    X = student_data[features].copy()\n",
    "    X = X.fillna(X.mean())\n",
    "    \n",
    "    # Standardize\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Perform clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    clusters = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    # Add clusters to data\n",
    "    student_data['Cluster'] = clusters\n",
    "    \n",
    "    # Get cluster profiles\n",
    "    cluster_profiles = student_data.groupby('Cluster')[features].mean().to_dict()\n",
    "    \n",
    "    # Get cluster sizes\n",
    "    cluster_sizes = student_data['Cluster'].value_counts().sort_index().to_dict()\n",
    "    \n",
    "    # PCA for visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='viridis', alpha=0.6, s=50)\n",
    "    ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})')\n",
    "    ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')\n",
    "    ax.set_title(f'Student Clusters (k={n_clusters})')\n",
    "    plt.colorbar(scatter, ax=ax, label='Cluster')\n",
    "    \n",
    "    return jsonify({\n",
    "        'n_clusters': n_clusters,\n",
    "        'features_used': features,\n",
    "        'cluster_profiles': cluster_profiles,\n",
    "        'cluster_sizes': cluster_sizes,\n",
    "        'cluster_visualization': fig_to_base64(fig),\n",
    "        'explained_variance': pca.explained_variance_ratio_.tolist()\n",
    "    })\n",
    "\n",
    "# ============================================\n",
    "# API Routes - Model Management\n",
    "# ============================================\n",
    "\n",
    "@app.route('/models/train', methods=['POST'])\n",
    "def train_model():\n",
    "    \"\"\"Train and save a machine learning model\"\"\"\n",
    "    global student_data, trained_models\n",
    "    \n",
    "    if student_data is None:\n",
    "        return jsonify({'error': 'No data loaded'}), 400\n",
    "    \n",
    "    data = request.json\n",
    "    model_name = data.get('model_name', 'default_model')\n",
    "    model_type = data.get('model_type', 'random_forest')\n",
    "    problem_type = data.get('problem_type', 'regression')\n",
    "    features = data.get('features', ['StudyTimeWeekly', 'Absences', 'ParentalSupport', 'TotalActivities'])\n",
    "    target = data.get('target', 'GPA')\n",
    "    \n",
    "    # Prepare data\n",
    "    X = student_data[features]\n",
    "    y = student_data[target]\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Select model\n",
    "    if problem_type == 'regression':\n",
    "        if model_type == 'random_forest':\n",
    "            model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        elif model_type == 'linear':\n",
    "            model = LinearRegression()\n",
    "        else:\n",
    "            model = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "    else:\n",
    "        if model_type == 'random_forest':\n",
    "            model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        elif model_type == 'logistic':\n",
    "            model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        else:\n",
    "            model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    if problem_type == 'regression':\n",
    "        metrics = {\n",
    "            'r2_score': r2_score(y_test, y_pred),\n",
    "            'rmse': np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        }\n",
    "    else:\n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred)\n",
    "        }\n",
    "    \n",
    "    # Save model\n",
    "    trained_models[model_name] = {\n",
    "        'model': model,\n",
    "        'scaler': scaler,\n",
    "        'features': features,\n",
    "        'target': target,\n",
    "        'problem_type': problem_type,\n",
    "        'model_type': model_type,\n",
    "        'metrics': metrics,\n",
    "        'test_size': 0.2\n",
    "    }\n",
    "    \n",
    "    return jsonify({\n",
    "        'message': f'Model \"{model_name}\" trained successfully',\n",
    "        'model_name': model_name,\n",
    "        'model_type': model_type,\n",
    "        'problem_type': problem_type,\n",
    "        'features': features,\n",
    "        'target': target,\n",
    "        'metrics': metrics\n",
    "    })\n",
    "\n",
    "@app.route('/models/predict/<model_name>', methods=['POST'])\n",
    "def predict_with_model(model_name):\n",
    "    \"\"\"Make predictions using a trained model\"\"\"\n",
    "    global trained_models\n",
    "    \n",
    "    if model_name not in trained_models:\n",
    "        return jsonify({'error': f'Model \"{model_name}\" not found'}), 404\n",
    "    \n",
    "    model_info = trained_models[model_name]\n",
    "    data = request.json\n",
    "    \n",
    "    # Prepare input data\n",
    "    input_data = {}\n",
    "    for feature in model_info['features']:\n",
    "        input_data[feature] = data.get(feature.lower(), 0)\n",
    "    \n",
    "    input_df = pd.DataFrame([input_data])\n",
    "    \n",
    "    # Scale features\n",
    "    input_scaled = model_info['scaler'].transform(input_df)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model_info['model'].predict(input_scaled)[0]\n",
    "    \n",
    "    # Get prediction probabilities for classification\n",
    "    probabilities = None\n",
    "    if model_info['problem_type'] == 'classification':\n",
    "        if hasattr(model_info['model'], 'predict_proba'):\n",
    "            probabilities = model_info['model'].predict_proba(input_scaled)[0].tolist()\n",
    "    \n",
    "    return jsonify({\n",
    "        'model_name': model_name,\n",
    "        'prediction': float(prediction) if isinstance(prediction, (int, float)) else str(prediction),\n",
    "        'probabilities': probabilities,\n",
    "        'input_features': input_data\n",
    "    })\n",
    "\n",
    "@app.route('/models/list', methods=['GET'])\n",
    "def list_models():\n",
    "    \"\"\"List all trained models\"\"\"\n",
    "    global trained_models\n",
    "    \n",
    "    models = []\n",
    "    for name, info in trained_models.items():\n",
    "        models.append({\n",
    "            'name': name,\n",
    "            'model_type': info['model_type'],\n",
    "            'problem_type': info['problem_type'],\n",
    "            'features': info['features'],\n",
    "            'target': info['target'],\n",
    "            'metrics': info['metrics']\n",
    "        })\n",
    "    \n",
    "    return jsonify({\n",
    "        'total_models': len(models),\n",
    "        'models': models\n",
    "    })\n",
    "\n",
    "# ============================================\n",
    "# API Routes - Export\n",
    "# ============================================\n",
    "\n",
    "@app.route('/export/data', methods=['GET'])\n",
    "def export_data():\n",
    "    \"\"\"Export processed data as CSV\"\"\"\n",
    "    global student_data\n",
    "    \n",
    "    if student_data is None:\n",
    "        return jsonify({'error': 'No data loaded'}), 400\n",
    "    \n",
    "    # Create CSV in memory\n",
    "    csv_buffer = io.StringIO()\n",
    "    student_data.to_csv(csv_buffer, index=False)\n",
    "    csv_buffer.seek(0)\n",
    "    \n",
    "    return send_file(\n",
    "        io.BytesIO(csv_buffer.getvalue().encode()),\n",
    "        mimetype='text/csv',\n",
    "        as_attachment=True,\n",
    "        download_name='student_performance_data.csv'\n",
    "    )\n",
    "\n",
    "@app.route('/export/report', methods=['GET'])\n",
    "def export_report():\n",
    "    \"\"\"Generate and export analysis report\"\"\"\n",
    "    global student_data\n",
    "    \n",
    "    if student_data is None:\n",
    "        return jsonify({'error': 'No data loaded'}), 400\n",
    "    \n",
    "    # Create report\n",
    "    report = []\n",
    "    report.append(\"=\"*60)\n",
    "    report.append(\"STUDENT PERFORMANCE ANALYSIS REPORT\")\n",
    "    report.append(\"=\"*60)\n",
    "    report.append(\"\")\n",
    "    \n",
    "    report.append(f\"Total Students: {len(student_data)}\")\n",
    "    report.append(f\"Average GPA: {student_data['GPA'].mean():.3f}\")\n",
    "    report.append(f\"Median Study Time: {student_data['StudyTimeWeekly'].median():.2f} hours\")\n",
    "    report.append(f\"Average Absences: {student_data['Absences'].mean():.2f}\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    report.append(\"GPA Distribution:\")\n",
    "    gpa_cats = [\n",
    "        ('Good (3.0-4.0)', student_data[student_data['GPA'] >= 3.0]),\n",
    "        ('Average (2.0-2.99)', student_data[(student_data['GPA'] >= 2.0) & (student_data['GPA'] < 3.0)]),\n",
    "        ('Below Average (1.0-1.99)', student_data[(student_data['GPA'] >= 1.0) & (student_data['GPA'] < 2.0)]),\n",
    "        ('Failing (0-0.99)', student_data[student_data['GPA'] < 1.0])\n",
    "    ]\n",
    "    \n",
    "    for cat_name, cat_data in gpa_cats:\n",
    "        count = len(cat_data)\n",
    "        percentage = (count / len(student_data)) * 100\n",
    "        report.append(f\"  {cat_name}: {count} students ({percentage:.1f}%)\")\n",
    "    \n",
    "    report.append(\"\")\n",
    "    report.append(\"Key Findings:\")\n",
    "    report.append(\"  1. Study time is positively correlated with GPA\")\n",
    "    report.append(\"  2. Absences negatively impact student performance\")\n",
    "    report.append(\"  3. Parental support significantly improves outcomes\")\n",
    "    report.append(\"  4. Extracurricular activities have positive effects\")\n",
    "    \n",
    "    report_text = \"\\n\".join(report)\n",
    "    \n",
    "    return send_file(\n",
    "        io.BytesIO(report_text.encode()),\n",
    "        mimetype='text/plain',\n",
    "        as_attachment=True,\n",
    "        download_name='student_performance_report.txt'\n",
    "    )\n",
    "\n",
    "# ============================================\n",
    "# Run the API\n",
    "# ============================================\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Generate sample data on startup\n",
    "    student_data = generate_sample_data(500)\n",
    "    print(\"âœ… Sample data generated with 500 students\")\n",
    "    print(\"ðŸš€ API running at http://localhost:5000\")\n",
    "    app.run(debug=True, host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fe9b6a-4152-4a96-afb9-02dff99017fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
